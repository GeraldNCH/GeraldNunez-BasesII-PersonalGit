# Bases II GR 1 - Resumen 3 - 21/03/2023

## Gerald Núñez Chavarría - 2021023226

###  Apache Spark: A Unified  Engine for  Big Data  Processing   

Apache Spark es un motor unificado para el procesamiento de datos distribuidos. Spark amplía el modelo de programación MapReduce con una abstracción de datos compartidos denominada Resilient Distributed Datasets (RDDs) para capturar una amplia gama de cargas de trabajo de procesamiento, incluyendo SQL, streaming, aprendizaje automático y procesamiento de gráficos. La generalidad de Spark tiene varias ventajas, como facilitar el desarrollo de aplicaciones, hacer más eficiente la combinación de tareas de procesamiento y permitir nuevas aplicaciones que no eran posibles con sistemas anteriores. Se puede comparar el valor de Spark con el de los smartphones, que unificaron las funciones de dispositivos portátiles independientes y permitieron nuevas aplicaciones que combinan sus funciones.

Apache Spark proporciona una plataforma unificada para diferentes tipos de procesamiento de datos, incluido el procesamiento por lotes, el streaming en tiempo real, el aprendizaje automático, el procesamiento de gráficos y el procesamiento SQL. Esto significa que Spark puede utilizarse para crear una amplia gama de aplicaciones, desde sencillos trabajos por lotes hasta complejas cadenas de análisis. 

Spark se desarrolló en el AMPLab de la Universidad de Berkeley en 2009 como alternativa de código abierto al marco Hadoop MapReduce. A diferencia de MapReduce, que se basa en el almacenamiento en disco y requiere varias pasadas sobre los datos para completar un trabajo, Spark está diseñado para el procesamiento en memoria. Esto permite a Spark realizar cálculos mucho más rápido que MapReduce, lo que lo hace idóneo para algoritmos iterativos y análisis de datos interactivos.

La arquitectura central de Spark se basa en una estructura de datos distribuidos denominada Resilient Distributed Datasets (RDD). Los RDD son colecciones inmutables de datos que pueden procesarse en paralelo en un clúster de nodos. Los RDDs proporcionan tolerancia a fallos mediante la replicación automática de los datos a través de múltiples nodos, de modo que en caso de fallo, los datos pueden ser recuperados sin ninguna pérdida de información, característica sumamente valiosa para cualquier administrador de datos. 

Spark proporciona varias APIs para trabajar con RDDs, incluyendo la API central en Scala, Java y Python, así como APIs de más alto nivel como Spark SQL, Spark Streaming y MLlib. Spark SQL proporciona una interfaz similar a SQL para trabajar con datos estructurados, mientras que Spark Streaming permite el procesamiento en tiempo real de datos en streaming. MLlib es una biblioteca de aprendizaje automático escalable que proporciona una variedad de algoritmos de clasificación, regresión, agrupación y filtrado colaborativo.

Spark también se integra con otras tecnologías de big data como Hadoop, Cassandra y Apache Kafka, lo que le permite leer y escribir datos de diversas fuentes. Se puede también ejecutar Spark en diferentes gestores de clústeres como Hadoop YARN, Apache Mesos y Kubernetes, lo que ofrece a los usuarios diversas opciones de despliegue.

Una de las principales ventajas de Spark es su velocidad. Dado que Spark mantiene los datos en memoria, puede realizar cálculos mucho más rápido que los sistemas basados en disco como MapReduce. Spark también admite la evaluación perezosa, lo que significa que no ejecuta los cálculos hasta que se necesitan los resultados. Esto permite optimizar las cadenas de procesamiento de datos computando únicamente los datos que realmente se necesitan, lo que puede ahorrar tiempo y recursos.

Otra ventaja de Spark es su escalabilidad. Spark está diseñado para escalar horizontalmente a través de un clúster de nodos, lo que significa que a medida que crecen los volúmenes de datos, se pueden añadir más nodos al clúster para manejar la carga adicional. Spark también proporciona tolerancia a fallos integrada, lo que significa que en caso de fallo de un nodo, el procesamiento puede continuar en otros nodos sin ninguna interrupción.

A partir de las resumidas características que se han dado, se puede apreciar que Apache Spark es un motor de procesamiento de big data potente y flexible que proporciona una plataforma unificada para diferentes tipos de procesamiento de datos. Su velocidad, escalabilidad y facilidad de uso lo han convertido en una opción popular para crear aplicaciones de datos a gran escala. Con su creciente popularidad y su amplia gama de casos de uso, es probable que Spark siga siendo una tecnología clave en el panorama del procesamiento de big data en los próximos años.

